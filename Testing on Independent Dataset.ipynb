{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing on Independent Dataset.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oxFvcpDSTR4m","colab_type":"code","outputId":"35066227-c5fb-406a-9757-d708798fba44","executionInfo":{"status":"ok","timestamp":1569359801955,"user_tz":-300,"elapsed":202912,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j5caLLHJTdrE","colab_type":"code","colab":{}},"source":["# In following sections, the g-gap features are further processed to test CNN\n","c=\"/content/drive/My Drive/Colab Notebooks/allseq_ind.csv\"\n","with open(c) as f:\n","    content = f.read() \n","s=0\n","dat=content.split(\"\\n\") \n","for i in dat:\n","    dat[s]=list(dat[s])\n","    s=s+1\n","          \n","\n","    \n","import numpy as np\n","lm=1\n","tp=np.zeros(772)\n","for h in range(772):\n","    tp[h]=len(dat[lm])\n","    lm=lm+2\n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/zero_ind.csv\"\n","with open(c) as f:\n","    content0 = f.read() \n","    \n","dat0=content0.split(\"\\n\") \n","s=0\n","for i in range(len(dat0)):\n","    dat0[s]=dat0[s].split(\",\")\n","    s=s+1\n","    \n","   \n","import numpy as np\n","dataaa0=np.zeros((772,400))\n","ii=0; jj=0\n","for i in range(772):\n","    for j in range(400):\n","        dataaa0[i][j]=float(dat0[i][j])\n","        \n","tc=0\n","for i in range(772):\n","    tc=tp[i]-1\n","    dataaa0[i]=dataaa0[i]*tc\n","    \n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/one_ind.csv\"\n","with open(c) as f:\n","    content1 = f.read() \n","    \n","dat1=content1.split(\"\\n\") \n","s=0\n","for i in range(len(dat1)):\n","    dat1[s]=dat1[s].split(\",\")\n","    s=s+1\n","    \n","   \n","import numpy as np\n","dataaa1=np.zeros((772,400))\n","ii=0; jj=0\n","for i in range(772):\n","    for j in range(400):\n","        dataaa1[i][j]=float(dat1[i][j])\n","        \n","tc=0\n","for i in range(772):\n","    tc=tp[i]-1\n","    dataaa1[i]=dataaa1[i]*tc\n","    \n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/two_ind.csv\"\n","with open(c) as f:\n","    content2 = f.read() \n","    \n","dat2=content2.split(\"\\n\") \n","s=0\n","for i in range(len(dat2)):\n","    dat2[s]=dat2[s].split(\",\")\n","    s=s+1\n","    \n","   \n","import numpy as np\n","dataaa2=np.zeros((772,400))\n","ii=0; jj=0\n","for i in range(772):\n","    for j in range(400):\n","        dataaa2[i][j]=float(dat2[i][j])\n","        \n","tc=0\n","for i in range(772):\n","    tc=tp[i]-1\n","    dataaa2[i]=dataaa2[i]*tc\n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/three_ind.csv\"\n","with open(c) as f:\n","    content3 = f.read() \n","    \n","dat3=content3.split(\"\\n\") \n","s=0\n","for i in range(len(dat3)):\n","    dat3[s]=dat3[s].split(\",\")\n","    s=s+1\n","    \n","   \n","import numpy as np\n","dataaa3=np.zeros((772,400))\n","ii=0; jj=0\n","for i in range(772):\n","    for j in range(400):\n","        dataaa3[i][j]=float(dat3[i][j])\n","        \n","tc=0\n","for i in range(772):\n","    tc=tp[i]-1\n","    dataaa3[i]=dataaa3[i]*tc "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qe21T3wcloUU","colab_type":"code","colab":{}},"source":["a = np.reshape(dataaa0,[772,20,20])\n","b = np.reshape(dataaa1,[772,20,20])\n","c = np.reshape(dataaa2,[772,20,20])\n","feature1=np.zeros((772,20,20,3))\n","for i in range(772):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature1[i]=data                \n","                  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6jw9cRFT5ft","colab_type":"code","colab":{}},"source":["a = np.reshape(dataaa0,[772,20,20])\n","b = np.reshape(dataaa1,[772,20,20])\n","c = np.reshape(dataaa3,[772,20,20])\n","feature2=np.zeros((772,20,20,3))\n","for i in range(772):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature2[i]=data "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePRsSm3elvEm","colab_type":"code","colab":{}},"source":["a = np.reshape(dataaa0,[772,20,20])\n","b = np.reshape(dataaa2,[772,20,20])\n","c = np.reshape(dataaa3,[772,20,20])\n","feature3=np.zeros((772,20,20,3))\n","for i in range(772):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature3[i]=data                \n","                  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcnqaR4BlykJ","colab_type":"code","colab":{}},"source":["a = np.reshape(dataaa1,[772,20,20])\n","b = np.reshape(dataaa2,[772,20,20])\n","c = np.reshape(dataaa3,[772,20,20])\n","feature4=np.zeros((772,20,20,3))\n","for i in range(772):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature4[i]=data     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"--WrtI6Rl2kT","colab_type":"code","colab":{}},"source":["import numpy as np\n","label=np.zeros(772)\n","for i in range(386):\n","    label[i]=0\n","j=386  \n","for k in range(386):\n","    label[j]=1\n","    j=j+1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"63clBoEDdExJ","colab_type":"code","outputId":"1adc8bdc-bc06-46d4-d488-de2ffeb98c88","executionInfo":{"status":"ok","timestamp":1569359828424,"user_tz":-300,"elapsed":4617,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os,cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","from keras import backend as K\n","K.set_image_data_format('channels_last')\n","\n","\n","\n","\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers  import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD,RMSprop,adam# \n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import StratifiedKFold\n","import numpy\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import numpy"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GbiF4k5kl5ZE","colab_type":"code","outputId":"572f42be-437f-409d-92d7-a62aed925a89","executionInfo":{"status":"ok","timestamp":1569359838230,"user_tz":-300,"elapsed":8811,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":533}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,22.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature1[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","# load pima indians dataset\n","p1=model.predict_classes(feature1) #................\n","#pre.apppend(t1)\n","from sklearn.metrics import confusion_matrix\n","cm1 = confusion_matrix(label, p1)#...............................\n","print(cm1)\n","total1=sum(sum(cm1))\n","accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","print(accuracy1)\n","scores = model.evaluate(feature1, label, verbose=0)#.............................\n","print(scores)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Created model and loaded weights from file\n","[[290  96]\n"," [ 56 330]]\n","0.8031088082901554\n","[0.6216259994664727, 0.8031088082901554]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tjy2LSulrRUx","colab_type":"code","outputId":"ed68e7c8-2b9b-416b-be2d-72b7cd496aaf","executionInfo":{"status":"ok","timestamp":1569359844315,"user_tz":-300,"elapsed":1601,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature2[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","# load pima indians dataset\n","p2=model.predict_classes(feature2) #................\n","#pre.apppend(t1)\n","from sklearn.metrics import confusion_matrix\n","cm1 = confusion_matrix(label, p2)#...............................\n","print(cm1)\n","total1=sum(sum(cm1))\n","accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","print(accuracy1)\n","scores = model.evaluate(feature2, label, verbose=0)#.............................\n","print(scores)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n","[[298  88]\n"," [ 55 331]]\n","0.8147668393782384\n","[0.7013261653096874, 0.8147668393782384]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1MrwO3QHrRkj","colab_type":"code","outputId":"be174f48-1960-446d-d70a-3b139e8d6fec","executionInfo":{"status":"ok","timestamp":1569359849051,"user_tz":-300,"elapsed":2353,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,2,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature3[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","# load pima indians dataset\n","p3=model.predict_classes(feature3) #................\n","#pre.apppend(t1)\n","from sklearn.metrics import confusion_matrix\n","cm1 = confusion_matrix(label, p3)#...............................\n","print(cm1)\n","total1=sum(sum(cm1))\n","accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","print(accuracy1)\n","scores = model.evaluate(feature3, label, verbose=0)#.............................\n","print(scores)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n","[[309  77]\n"," [ 59 327]]\n","0.8238341968911918\n","[0.5960961967475056, 0.8238341968911918]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"syb9WpocrSXU","colab_type":"code","outputId":"b13a8689-3d8e-484b-bfc7-05826bcdb621","executionInfo":{"status":"ok","timestamp":1569359852820,"user_tz":-300,"elapsed":2156,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-1,2,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature4[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","# load pima indians dataset\n","p4=model.predict_classes(feature4) #................\n","#pre.apppend(t1)\n","from sklearn.metrics import confusion_matrix\n","cm1 = confusion_matrix(label, p4)#...............................\n","print(cm1)\n","total1=sum(sum(cm1))\n","accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","print(accuracy1)\n","scores = model.evaluate(feature4, label, verbose=0)#.............................\n","print(scores)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n","[[312  74]\n"," [ 50 336]]\n","0.8393782383419689\n","[0.5031714298294307, 0.8393782383419689]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Nx6mAjel-SE","colab_type":"code","colab":{}},"source":["featureee=np.zeros((772,4))\n","for i in range(772):\n","  featureee[i,0]=p1[i]\n","  featureee[i,1]=p2[i]\n","  featureee[i,2]=p3[i]\n","  featureee[i,3]=p4[i]\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmNUNDwkmCOk","colab_type":"code","outputId":"d4919f7f-9288-4785-8bb3-0cdf8df71a4b","executionInfo":{"status":"ok","timestamp":1569359859699,"user_tz":-300,"elapsed":1135,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"source":["c=\"/content/drive/My Drive/Colab Notebooks/allseq_ind.csv\"\n","with open(c) as f:\n","    content = f.read() \n","s=0\n","dat=content.split(\"\\n\") \n","for i in dat:\n","    dat[s]=list(dat[s])\n","    s=s+1\n","import numpy as np    \n","feature = np.zeros((772,20,))\n","print(feature)  \n","ppp=20\n","aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0; \n","sss=0;\n","spsp=1;\n","\n","\n","for i in range(772):\n","    word = dat[spsp]\n","    v=0\n","    for l in word:\n","        if word[v]=='A':\n","            aa=aa+1\n","        elif word[v]=='R':\n","            rr=rr+1\n","        elif word[v]=='N':\n","            nn=nn+1\n","        elif word[v]=='D':\n","            dd=dd+1\n","        elif word[v]=='C':\n","            cc=cc+1\n","        elif word[v]=='Q':\n","            qq=qq+1\n","        elif word[v]=='E':\n","            ee=ee+1\n","        elif word[v]=='G':\n","            gg=gg+1\n","        elif word[v]=='H':\n","            hh=hh+1\n","        elif word[v]=='I':\n","            ii=ii+1\n","        elif word[v]=='L':\n","            ll=ll+1\n","        elif word[v]=='K':\n","            kk=kk+1\n","        elif word[v]=='M':\n","            mm=mm+1\n","        elif word[v]=='F':\n","            ff=ff+1\n","        elif word[v]=='P':\n","            pp=pp+1\n","        elif word[v]=='S':\n","            ss=ss+1\n","        elif word[v]=='T':\n","            tt=tt+1\n","        elif word[v]=='W':\n","            ww=ww+1\n","        elif word[v]=='Y':\n","            yy=yy+1\n","        else:\n","            vv=vv+1\n","        v=v+1    \n","    \n","    #aa=aa/20; rr=rr/20; nn=nn/20; dd=dd/20; cc=cc/20; qq=qq/20; ee=ee/20; gg=gg/20; hh=hh/20; ii=ii/20; ll=ll/20; kk=kk/20; mm=mm/20; ff=ff/20; pp=pp/20; ss=ss/20; tt=tt/20; ww=ww/20; yy=yy/20; vv=vv/20;\n","    feature[sss][0]=aa; feature[sss][1]=rr; feature[sss][2]=nn; feature[sss][3]=dd; feature[sss][4]=cc; feature[sss][5]=qq; feature[sss][6]=ee; feature[sss][7]=gg; feature[sss][8]=hh; feature[sss][9]=ii; feature[sss][10]=ll; feature[sss][11]=kk; feature[sss][12]=mm; feature[sss][13]=ff; feature[sss][14]=pp; feature[sss][15]=ss; feature[sss][16]=tt; feature[sss][17]=ww; feature[sss][18]=yy; feature[sss][19]=vv; \n","    aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0;\n","    sss=sss+1\n","    spsp=spsp+2"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fkhKLGh0mIRc","colab_type":"code","colab":{}},"source":["inputt=np.zeros((772,24))\n","inputt[:,0:4]=featureee[:,:]\n","inputt[:,4:]=feature[:,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4gOcxVomMKP","colab_type":"code","outputId":"05560486-f9e6-4b4e-a461-cbc48029f24c","executionInfo":{"status":"ok","timestamp":1569359865240,"user_tz":-300,"elapsed":1551,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pickle\n","filename='/content/drive/My Drive/Colab Notebooks/new-svm-benc10-4.sav'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","result = loaded_model.score(inputt, label)\n","result1=loaded_model.predict(inputt)\n","print(result)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["0.9002590673575129\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r2e82ZwLmRYT","colab_type":"code","outputId":"ea00c0be-3041-4cc6-9d1d-239f051f782d","executionInfo":{"status":"ok","timestamp":1569359873066,"user_tz":-300,"elapsed":1455,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["cm1 = confusion_matrix(label, result1)\n","sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n","print('Sensitivity : ', sensitivity1 )\n","\n","specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n","print('Specificity : ', specificity1)\n","tp=cm1[0,0]\n","print('tp : ', tp)\n","fp=cm1[0,1]\n","print('fp : ', fp)\n","fn=cm1[1,0]\n","print('fn : ', fn)\n","tn=cm1[1,0]\n","print('tn : ', tn)\n","#%%\n","from sklearn.metrics import matthews_corrcoef\n","mcc = matthews_corrcoef(label,result1)\n","print('Matthews Correlation Coefficient:', mcc)\n","\n","  #%%\n","total1=sum(sum(cm1))\n","\n","accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","print ('Accuracy : ', accuracy1)\n","\n","import numpy as np\n","from sklearn import metrics\n","fpr, tpr, thresholds = metrics.roc_curve(label, result1)\n","aucc=metrics.auc(fpr, tpr)\n","print('AUC:', aucc)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Sensitivity :  0.9637305699481865\n","Specificity :  0.8367875647668394\n","tp :  372\n","fp :  14\n","fn :  63\n","tn :  63\n","Matthews Correlation Coefficient: 0.807047135736267\n","Accuracy :  0.9002590673575129\n","AUC: 0.9002590673575129\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mPU8unNymW3c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}