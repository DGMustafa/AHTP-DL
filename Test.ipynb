{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EyTW0CM6zuk1","colab_type":"text"},"source":["# Run each cell one by one "]},{"cell_type":"code","metadata":{"id":"U1-KOO4Jt1Fk","colab_type":"code","outputId":"d4d6aa49-bfa3-4201-b6ec-cb0298703079","executionInfo":{"status":"ok","timestamp":1569268783549,"user_tz":-300,"elapsed":80116,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EugssN_J-wsR","colab_type":"code","outputId":"1a77e45d-3055-4dca-aaa7-c9809bf0cb37","executionInfo":{"status":"ok","timestamp":1569280324382,"user_tz":-300,"elapsed":1003,"user":{"displayName":"namra anum","photoUrl":"","userId":"11372364156286165653"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["%cd /content/drive/My Drive/Colab Notebooks/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/'\n","/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JLIH0suB2sQn","colab_type":"text"},"source":["**Before running next cell, read the instruction**"]},{"cell_type":"code","metadata":{"id":"0if_esYUCo-F","colab_type":"code","outputId":"d25b0dfc-7997-4b69-faf1-8ee39d236e77","executionInfo":{"status":"ok","timestamp":1569268817791,"user_tz":-300,"elapsed":10498,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["\n","#In the following code  tes3.txt is the file in which test peptides is\n","# Replace tes3.txt with any file which need to be predict.\n","# The file format must be .txt or .csv\n","# The test file must be in the folder in which all code files are\n","# test peptides must be in fasta format\n","# Test Peptides must be greater or equal to 5 length.\n","# Examples of fasta format file:\n","\n","#    >peptide_0\n","#    AAAWWN\n","#    >peptide_1\n","#    ANAVRN\n","\n","# where \"peptide\" word can be changed or anything else but \"_\" , and  \">\" must same as it is and the number of example must be in ascending order (i.e. 0,1,2,3....) \n","\n","\n","\n","!python g-gap.py -g 0 -i tes3.txt -o DPC-Features-gap-0.csv\n","!python g-gap.py -g 1 -i tes3.txt -o DPC-Features-gap-1.csv\n","!python g-gap.py -g 2 -i tes3.txt -o DPC-Features-gap-2.csv\n","!python g-gap.py -g 3 -i tes3.txt -o DPC-Features-gap-3.csv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------Finished!------\n","------Finished!------\n","------Finished!------\n","------Finished!------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qOpc_Wso2hw0","colab_type":"text"},"source":["**Run all remaining cells without any changes**"]},{"cell_type":"code","metadata":{"id":"EjSmbJdixx58","colab_type":"code","colab":{}},"source":["c=\"/content/drive/My Drive/Colab Notebooks/tes3.txt\"  #Folder path in drive where all sequences of test dataset is.\n","with open(c) as f:\n","    content = f.read() \n","s=0\n","dat=content.split(\"\\n\") \n","for i in dat:\n","    dat[s]=list(dat[s])\n","    s=s+1\n","\n","dd=len(dat)\n","ddd=dd/2\n","dddd=int(ddd)\n","import numpy as np\n","lm=1\n","tp=np.zeros(dddd)\n","for h in range(dddd):\n","    tp[h]=len(dat[lm])\n","    lm=lm+2\n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/DPC-Features-gap-0.csv\"  #Folder path in drive where all g-gap DPC features with gap 0 is.\n","with open(c) as f:\n","    content0 = f.read() \n","    \n","dat0=content0.split(\"\\n\") \n","s=1\n","for i in range(len(dat0)-1):\n","    dat0[s]=dat0[s].split(\",\")\n","    s=s+1\n","\n","newdat0=dat0[1:]\n","import numpy as np\n","dataaa0=np.zeros((dddd,401))\n","ii=0; jj=0\n","for i in range(dddd):\n","    for j in range(401):\n","        dataaa0[i][j]=float(newdat0[i][j])\n","        \n","newdataaa0=np.zeros((dddd,400))\n","for i in range(dddd):\n","    newdataaa0[i][:]=dataaa0[i][1:401]\n","    \n","tc=0\n","for i in range(dddd):\n","    tc=tp[i]-1\n","    newdataaa0[i]=newdataaa0[i]*tc \n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/DPC-Features-gap-1.csv\"  #Folder path in drive where all g-gap DPC features with gap 1 is.\n","with open(c) as f:\n","    content1 = f.read() \n","    \n","dat1=content1.split(\"\\n\") \n","s=1\n","for i in range(len(dat1)-1):\n","    dat1[s]=dat1[s].split(\",\")\n","    s=s+1\n","\n","newdat1=dat1[1:]\n","import numpy as np\n","dataaa1=np.zeros((dddd,401))\n","ii=0; jj=0\n","for i in range(dddd):\n","    for j in range(401):\n","        dataaa1[i][j]=float(newdat1[i][j])\n","        \n","newdataaa1=np.zeros((dddd,400))\n","for i in range(dddd):\n","    newdataaa1[i][:]=dataaa1[i][1:401]\n","    \n","tc=0\n","for i in range(dddd):\n","    tc=tp[i]-1\n","    newdataaa1[i]=newdataaa1[i]*tc\n","    \n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/DPC-Features-gap-2.csv\"  #Folder path in drive where all g-gap DPC features with gap 2 is.\n","with open(c) as f:\n","    content2 = f.read() \n","    \n","dat2=content2.split(\"\\n\") \n","s=1\n","for i in range(len(dat2)-1):\n","    dat2[s]=dat2[s].split(\",\")\n","    s=s+1\n","\n","newdat2=dat2[1:]\n","import numpy as np\n","dataaa2=np.zeros((dddd,401))\n","ii=0; jj=0\n","for i in range(dddd):\n","    for j in range(401):\n","        dataaa2[i][j]=float(newdat2[i][j])\n","        \n","newdataaa2=np.zeros((dddd,400))\n","for i in range(dddd):\n","    newdataaa2[i][:]=dataaa2[i][1:401]\n","    \n","tc=0\n","for i in range(dddd):\n","    tc=tp[i]-1\n","    newdataaa2[i]=newdataaa2[i]*tc\n","    \n","#%%\n","c=\"/content/drive/My Drive/Colab Notebooks/DPC-Features-gap-3.csv\"  #Folder path in drive where all g-gap DPC features with gap 3 is.\n","with open(c) as f:\n","    content3 = f.read() \n","    \n","dat3=content3.split(\"\\n\") \n","s=1\n","for i in range(len(dat3)-1):\n","    dat3[s]=dat3[s].split(\",\")\n","    s=s+1\n","\n","newdat3=dat3[1:]\n","import numpy as np\n","dataaa3=np.zeros((dddd,401))\n","ii=0; jj=0\n","for i in range(dddd):\n","    for j in range(401):\n","        dataaa3[i][j]=float(newdat3[i][j])\n","        \n","newdataaa3=np.zeros((dddd,400))\n","for i in range(dddd):\n","    newdataaa3[i][:]=dataaa3[i][1:401]\n","    \n","tc=0\n","for i in range(dddd):\n","    tc=tp[i]-1\n","    newdataaa3[i]=newdataaa3[i]*tc\n","#%%\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4jxS6ovo3xhH","colab_type":"code","colab":{}},"source":["#Images for DPC features with gap 0,1,2\n","a = np.reshape(newdataaa0,[dddd,20,20])\n","b = np.reshape(newdataaa1,[dddd,20,20])\n","c = np.reshape(newdataaa2,[dddd,20,20])\n","feature1=np.zeros((dddd,20,20,3))\n","for i in range(dddd):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature1[i]=data     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bjH3F3Bgl66","colab_type":"code","colab":{}},"source":["#Images for DPC features with gap 0,1,3\n","a = np.reshape(newdataaa0,[dddd,20,20])\n","b = np.reshape(newdataaa1,[dddd,20,20])\n","c = np.reshape(newdataaa3,[dddd,20,20])\n","feature2=np.zeros((dddd,20,20,3))\n","for i in range(dddd):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature2[i]=data "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0I1OymUgqdp","colab_type":"code","colab":{}},"source":["#Images for DPC features with gap 0,2,3\n","a = np.reshape(newdataaa0,[dddd,20,20])\n","b = np.reshape(newdataaa2,[dddd,20,20])\n","c = np.reshape(newdataaa3,[dddd,20,20])\n","feature3=np.zeros((dddd,20,20,3))\n","for i in range(dddd):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature3[i]=data "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"06_3sUJQgu67","colab_type":"code","colab":{}},"source":["#Images for DPC features with gap 1,2,3\n","a = np.reshape(newdataaa1,[dddd,20,20])\n","b = np.reshape(newdataaa2,[dddd,20,20])\n","c = np.reshape(newdataaa3,[dddd,20,20])\n","feature4=np.zeros((dddd,20,20,3))\n","for i in range(dddd):\n","  data = np.zeros( (20,20,3))\n","  data[:,:,0]=a[i,:,:]\n","  data[:,:,1]=b[i,:,:]\n","  data[:,:,2]=c[i,:,:]\n","  feature4[i]=data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDwHTalvhnGJ","colab_type":"code","outputId":"4bbf023a-dc78-47ee-8493-e48deffd910b","executionInfo":{"status":"ok","timestamp":1569268844776,"user_tz":-300,"elapsed":3358,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os,cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","from keras import backend as K\n","K.set_image_data_format('channels_last')\n","\n","\n","\n","\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers  import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD,RMSprop,adam# \n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import StratifiedKFold\n","import numpy\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import numpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z7_JY_-oiPm9","colab_type":"code","outputId":"442b515b-f3b6-4e30-a93c-d4d918ea8e1e","executionInfo":{"status":"ok","timestamp":1569269265702,"user_tz":-300,"elapsed":1027,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,22.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature1[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","\n","p1=model.predict_classes(feature1) #................\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WDcQc4bvtn-9","colab_type":"code","outputId":"7419fbe7-b577-4b81-f9b8-946de37748e0","executionInfo":{"status":"ok","timestamp":1569269268876,"user_tz":-300,"elapsed":1052,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature2[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","\n","p2=model.predict_classes(feature2) #................"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t-53F1L1t4oV","colab_type":"code","outputId":"848edf83-048e-4e74-aae8-bac0337a74fe","executionInfo":{"status":"ok","timestamp":1569269272607,"user_tz":-300,"elapsed":1002,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,2,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature3[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","\n","p3=model.predict_classes(feature3) #................"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nOhZ3x82t_gd","colab_type":"code","outputId":"88da44aa-8aac-4354-e315-812878c966f7","executionInfo":{"status":"ok","timestamp":1569269274977,"user_tz":-300,"elapsed":1048,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-1,2,32.hdf5\" #.............................\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), border_mode='valid', input_shape=feature4[0].shape)) #............................\n","convout1 = Activation('relu')\n","model.add(convout1)\n","convout3 = Activation('relu')\n","model.add(convout3)\n","model.add(Conv2D(8,( 3, 3)))\n","  \n","model.add(MaxPooling2D(pool_size=(2,2 )))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(170))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","# load weights\n","model.load_weights(filepath)\n","# Compile model (required to make predictions)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n","print(\"Created model and loaded weights from file\")\n","\n","p4=model.predict_classes(feature4) #................"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(20, 20, 3..., padding=\"valid\")`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Created model and loaded weights from file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tvEkW_uvuF4i","colab_type":"code","colab":{}},"source":["featureee=np.zeros((dddd,4))\n","for i in range(dddd):\n","  featureee[i,0]=p1[i]\n","  featureee[i,1]=p2[i]\n","  featureee[i,2]=p3[i]\n","  featureee[i,3]=p4[i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkupuNB2vOIn","colab_type":"code","outputId":"8408a615-720b-4928-8b38-0668040d94fa","executionInfo":{"status":"ok","timestamp":1569269502628,"user_tz":-300,"elapsed":1815,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["c=\"/content/drive/My Drive/Colab Notebooks/tes3.txt\"\n","with open(c) as f:\n","    content = f.read() \n","s=0\n","dat=content.split(\"\\n\") \n","for i in dat:\n","    dat[s]=list(dat[s])\n","    s=s+1\n","import numpy as np    \n","feature = np.zeros((dddd,20,))\n","print(feature)  \n","ppp=20\n","aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0; \n","sss=0;\n","spsp=1;\n","\n","\n","for i in range(dddd):\n","    word = dat[spsp]\n","    v=0\n","    for l in word:\n","        if word[v]=='A':\n","            aa=aa+1\n","        elif word[v]=='R':\n","            rr=rr+1\n","        elif word[v]=='N':\n","            nn=nn+1\n","        elif word[v]=='D':\n","            dd=dd+1\n","        elif word[v]=='C':\n","            cc=cc+1\n","        elif word[v]=='Q':\n","            qq=qq+1\n","        elif word[v]=='E':\n","            ee=ee+1\n","        elif word[v]=='G':\n","            gg=gg+1\n","        elif word[v]=='H':\n","            hh=hh+1\n","        elif word[v]=='I':\n","            ii=ii+1\n","        elif word[v]=='L':\n","            ll=ll+1\n","        elif word[v]=='K':\n","            kk=kk+1\n","        elif word[v]=='M':\n","            mm=mm+1\n","        elif word[v]=='F':\n","            ff=ff+1\n","        elif word[v]=='P':\n","            pp=pp+1\n","        elif word[v]=='S':\n","            ss=ss+1\n","        elif word[v]=='T':\n","            tt=tt+1\n","        elif word[v]=='W':\n","            ww=ww+1\n","        elif word[v]=='Y':\n","            yy=yy+1\n","        else:\n","            vv=vv+1\n","        v=v+1    \n","    \n","    #aa=aa/20; rr=rr/20; nn=nn/20; dd=dd/20; cc=cc/20; qq=qq/20; ee=ee/20; gg=gg/20; hh=hh/20; ii=ii/20; ll=ll/20; kk=kk/20; mm=mm/20; ff=ff/20; pp=pp/20; ss=ss/20; tt=tt/20; ww=ww/20; yy=yy/20; vv=vv/20;\n","    feature[sss][0]=aa; feature[sss][1]=rr; feature[sss][2]=nn; feature[sss][3]=dd; feature[sss][4]=cc; feature[sss][5]=qq; feature[sss][6]=ee; feature[sss][7]=gg; feature[sss][8]=hh; feature[sss][9]=ii; feature[sss][10]=ll; feature[sss][11]=kk; feature[sss][12]=mm; feature[sss][13]=ff; feature[sss][14]=pp; feature[sss][15]=ss; feature[sss][16]=tt; feature[sss][17]=ww; feature[sss][18]=yy; feature[sss][19]=vv; \n","    aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0;\n","    sss=sss+1\n","    spsp=spsp+2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iCK6VfXKv_RW","colab_type":"code","colab":{}},"source":["inputt=np.zeros((dddd,24))\n","inputt[:,0:4]=featureee[:,:]\n","inputt[:,4:]=feature[:,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzChcZkUwV0-","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC  \n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","from sklearn import svm\n","from sklearn.svm import SVC  \n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","from sklearn import svm\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","from sklearn import svm  \n","from sklearn.metrics import classification_report, confusion_matrix\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEu0FYLWwpyw","colab_type":"code","outputId":"2d5fd418-95a5-471e-83cd-44583ccf7b06","executionInfo":{"status":"ok","timestamp":1569269950326,"user_tz":-300,"elapsed":1115,"user":{"displayName":"namra anum","photoUrl":"","userId":"07446917439871629911"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pickle\n","filename='/content/drive/My Drive/Colab Notebooks/new-svm-benc10-4.sav'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","result1=loaded_model.predict(inputt)\n","print(result1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0. 0. 0.]\n"],"name":"stdout"}]}]}